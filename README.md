# TODO

- [ ] fix llm stream - to show tokens as they appear
- [ ] fix tts - mostly noise, but hearable text
- [ ] Divide output text on eos, feed to tts
- [ ] Full async multithread support
- [ ] Update LLM memory to persistence
- [ ] Add conversation summary
- [ ] Add loading conversation
